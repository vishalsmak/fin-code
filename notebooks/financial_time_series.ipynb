{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Data Preprocessing\n",
    "A time series is a series of data points indexed in time order. Financial Data such as equity, commodity, and forex price series observed at equally spaced points in time are an example of such a series. It is a sequence of data points observed at regular time intervals and depending on the frequency of observations, a time series may typically be in ticks, seconds, minutes, hourly, daily, weekly, monthly, quarterly and annual.\n",
    "\n",
    "The first step towards any data analysis would be to parse the raw data that involves extracting the data from the source and then cleaning and filling the missing data if any. While data comes in many forms, Python makes it easy to read time-series data using useful packages.\n",
    "\n",
    "In this session, we will retrieve and store both end-of-day and intraday data using some of the popular python packages. These libraries aim to keep the API simple and make it easier to access historical data. Further, we will see how to read data from traditional data sources stored locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings - optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import data manipulation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "        \n",
    "# Import yahoo finance library\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval\n",
    "Retrieving EOD, Intraday, Options data\n",
    "\n",
    "Retrieving end-of-day data for single security\n",
    "We'll retrieve historical data from yahoo finance using yfinance library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "# Fetch the data by specifying the number of period\n",
    "df1 = yf.download(\"AAPL\", period=\"10d\", progress=False)\n",
    "\n",
    "# Display the first five rows of the dataframe to check the results. \n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "# Fetch data by specifying the the start and end dates\n",
    "df2 = yf.download(\"AAPL\", start=\"2024-01-01\", end=\"2024-01-31\", progress=False)\n",
    "\n",
    "# Display the first five rows of the dataframe to check the results. \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last five rows\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3\n",
    "# Fetch data for year to date (YTD)\n",
    "df3 = yf.download(\"AAPL\", period=\"ytd\", progress=False)\n",
    "\n",
    "# Display the last five rows of the dataframe to check the results. \n",
    "df3.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving data for multiple securities\n",
    "We'll retrieve historical price data of five stocks from yahoo finance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify stocks\n",
    "# https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average\n",
    "dow_stocks = ['UNH', 'GS', 'HD', 'AMGN', 'MCD']\n",
    "dow_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data for multiple stocks at once\n",
    "df4 = yf.download(dow_stocks, period='ytd', progress=False)['Adj Close']\n",
    "\n",
    "# Display dataframe\n",
    "df4.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving multiple fields for multiple securities\n",
    "We'll now retrieve multiple fields from yahoo finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5\n",
    "# Group the stocks\n",
    "df5 = yf.download(dow_stocks, start=\"2024-06-01\", end=\"2024-06-30\", group_by=\"ticker\", progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display GS stock data\n",
    "df5['GS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving intraday data\n",
    "We'll now retrieve intraday data from yahoo finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 6\n",
    "# Retrieve intraday data for last five days\n",
    "df6 = yf.download('AAPL', period='5d', interval='1m', progress=False)\n",
    "\n",
    "# Display dataframe\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving option chain\n",
    "We'll now retrieve option chain for SPY for March 2024 expiration from yahoo finance and filter the output to display the first seven columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticker object\n",
    "spy = yf.Ticker('SPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy.options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SPY option chain for March 28th expiration\n",
    "# https://finance.yahoo.com/quote/SPY240930C00545000\n",
    "options = spy.option_chain('2024-09-30')\n",
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter calls for strike above 545\n",
    "df7 = options.calls[(options.calls['strike']>540) & (options.calls['strike']<550)]\n",
    "\n",
    "# Check the filtered output\n",
    "df7.iloc[:,:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving Hypertext Markup Language (HTML)\n",
    "We'll now retrieve India's benchmark index NIFTY50 Index data from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_html('https://en.wikipedia.org/wiki/NIFTY_50')[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from wikipedia\n",
    "nifty50 = pd.read_html('https://en.wikipedia.org/wiki/NIFTY_50')[2].Symbol.to_list()\n",
    "\n",
    "# Read five symbols\n",
    "nifty50[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Storage & Retrieval\n",
    "Let's store the data in the database and load back for manipulation.\n",
    "\n",
    "\n",
    "Storing Nifty50 data in SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 1\n",
    "\n",
    "# Import & create database \n",
    "# https://sqlite.org/cli.html\n",
    "from sqlalchemy import create_engine, text\n",
    "engine = create_engine('sqlite:///India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data from yahoo using list comprehension\n",
    "data = [yf.download(symbol+'.NS', period='250d', progress=False).reset_index() for symbol in nifty50] \n",
    "\n",
    "# save it to database\n",
    "for frame, symbol in zip(data, nifty50):\n",
    "    frame.to_sql(symbol, engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Sqlite Database\n",
    "# We'll now read the ohlcv data stored locally in the database using Pandas\n",
    "\n",
    "# Query from database\n",
    "query = 'SELECT * FROM  \"RELIANCE\" WHERE DATE > \"2024-06-01\"'\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    result = pd.read_sql_query(text(query), connection)\n",
    "\n",
    "# Display the results\n",
    "result.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Manipulation\n",
    "Next, we'll see some methods used in data wrangling. This is critical if you work on financial data or time series.\n",
    "\n",
    "Filter & Query Methods\n",
    "We'll now see some examples of subset selection using Panda's filter and query methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query from database\n",
    "query = 'SELECT * FROM  \"TITAN\"'\n",
    "with engine.connect() as connection:\n",
    "    df = pd.read_sql_query(text(query), connection)\n",
    "\n",
    "# Convert the date column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set the date column as the DataFrame index\n",
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first few days of data\n",
    "df.first('3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last few days of data\n",
    "df.last('3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter based on column\n",
    "df.filter(['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter based on row or index\n",
    "df.filter(like=\"2024-06-24\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for a specific condition. Ex: Close price > 3800\n",
    "df.query('Close>3800')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for condition where the difference between High and Low is greater than 150\n",
    "df.query('High-Low>150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for a multiple conditions. Ex: Close > 3700 and High-Low > 150\n",
    "df.query('Close>3700 & High-Low>150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for condition where Close>Open price\n",
    "df.query('Close>Open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for condition where Open price is equal to Low price of the day\n",
    "df.query('Open==Low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling data\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases\n",
    "# Resampling to derive weekly values from daily time series\n",
    "df_weekly = df.resample('W').last()\n",
    "\n",
    "# Display the last five rows of the data frame to check the output\n",
    "df_weekly.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases\n",
    "# Resampling to derive weekly values from daily time series\n",
    "df_weekly = df.resample('W').last()\n",
    "\n",
    "# Display the last five rows of the data frame to check the output\n",
    "df_weekly.tail()\n",
    "# Resampling to a specific day of the week: Thu\n",
    "df_weekly_thu = df.resample('W-THU').last()\n",
    "\n",
    "# Display the last five rows of the data frame to check the output\n",
    "df_weekly_thu.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling to derive monthly values from daily time series\n",
    "df_monthly = df.resample('M').last()\n",
    "\n",
    "# Display the last five rows of the data frame to check the output\n",
    "df_monthly.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Visualization of Time Series\n",
    "We use cufflinks for interactive visualization. It is one of the most feature rich third-party wrapper around Plotly by Santos Jorge. It binds the power of plotly with the flexibility of pandas for easy plotting.\n",
    "\n",
    "When you import cufflinks library, all pandas data frames and series objects have a new method .iplot() attached to them which is similar to pandas' built-in .plot() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cufflinks for visualization\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Line Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close'].iplot(kind='line', title='Line Chart')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we'll plot the time series data in ohlc format.\n",
    "\n",
    "df[-30:].iplot(kind='ohlc', title='Bar Chart')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we'll plot an interactive candlestick chart.\n",
    "\n",
    "df[-30:].iplot(kind='candle', title='Candle Chart')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Selected Stocks\n",
    "\n",
    "# Use secondary axis\n",
    "df4[['GS', 'HD']].iplot(secondary_y='HD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting subplots\n",
    "# Use subplots\n",
    "df4[['GS', 'HD']].iplot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize plot\n",
    "df4.normalize().iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Return Series\n",
    "We'll now plot historical daily log normal return series using just one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Log Normal Returns\n",
    "# Use numpy log function to derive log normal returns\n",
    "daily_returns = np.log(df4).diff().dropna()\n",
    "\n",
    "# Display the last five rows of the data frame to check the output\n",
    "daily_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean Annual Returns\n",
    "(daily_returns.mean()*252*100).iplot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean Annualized Volatility\n",
    "(daily_returns.std()*np.sqrt(252)*100).iplot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate 5 days rolling returns, simply sum daily returns for 5 days as log returns are additive\n",
    "rolling_return = daily_returns.rolling(5).sum().dropna()\n",
    "\n",
    "# Display the last five rows of the data frame to check the output\n",
    "rolling_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Rolling Returns\n",
    "rolling_return.iplot(title='5-Days Rolling Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Series Statistics\n",
    "Statistics is a branch of mathematics that deals with collecting, interpreting, organization and interpretation of data. The two main categories of statistics are descriptive statistics and inferential statistics.\n",
    "\n",
    "Descriptive statistics help us to understand the data in a meaningful way and is an important part of data analysis. While inferential statistics allows us to infer trends and derive conclusion from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing the daily returns data\n",
    "daily_returns.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Normal Distribution\n",
    "A normal distribution is the most common and widely used distribution in statistics. It is popularly referred as a “bell curve” or “Gaussian curve”. Financial time series though random in short term, follows a log normal distribution on a longer time frame.\n",
    "\n",
    "Now that we have derived the daily log returns, we will plot this return distribution and check whether the stock returns follows log normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot log normal distribution of returns\n",
    "daily_returns.iplot(kind='histogram', title = 'Histogram of Daily Returns', subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation of returns\n",
    "daily_returns.corr().iplot(kind='heatmap', title=\"Correlation Matrix\", colorscale=\"Blues\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
